# CONCURRENCY FINAL PROJECT: JAMCAN

## 1. Team Name

Our team name is JamCan.

## 2. Group Members

Our members are Skylar, Tyler, Cece, and Roger.

## 3. Project

A collaborative canvas where users can share musical sounds with each other, in
real time, using an intuitive UI. The interface will be built using PyGame and
the rest of the application will be in Python.

## 4. Minimum and Maximum Deliverable

Minimum: A GUI-based program that displays a 2D grid for playing collaborative
music. The grid represents pitches on the x-axis and velocities on the y-axis.
When a client clicks on a part of the grid, they and all others in that grid's
room will hear a corresponding note. Multiple clients will be able to join a
"room," in which a single grid exists. Multiple clients can play music by
clicking and dragging over the grid. When one client plays sound by clicking on
the grid, all clients in the room will hear the note.

Maximum: We would extend the canvas app with a bevy of features:

- Clients may play drum loops in the room.
- Clients may record jam sessions and export the recorded sessions to a file.
- If the client hosting a room dies, another client automatically becomes the
host; this is made possible through our peer-to-peer architecture.
- Add ripples, delay, envelope, and other graphical or musical sparkles.

## 5. First Steps

Our first step is to develop a PTP architecture model for our application. On
our own, we will learn PyGame or another Python GUI package so we can start
programming swiftly. and After completing a formal initial design, we will begin
programming.

## 6. Biggest Problem

One of the largest problems that could come up is designing a distributed
system that shares sounds with low enough latency to accomplish the goal of
being live and collaborative.

## additional notes on libraries and getting noises and instruments to 
work in pygame. 

Although there is a bevy of ways to get noise to work in pygame midi and not 
midi, most are either a bit dated or require funds (tragically). Due to this 
we will be using flyidsynth a program for digital synthesizers as it supports
soundfount, and thus many digital instruments Given that fluidsynth is not 
python we will also be using the pyfluidsynth package, for fluidsynth bindings. 
To get our synths and sounds. For a demo see fuid-test.py examples. 

difficulties
One challenge we have already faced is library and version difficulty with 
correctly importing the pyfluidsynth library and fluidsynth, a tragic bug 
we encountered was getting both to work in a conda virtual environment, 
we refrenced these we will be using to play noises for the game. 
After refrencing https://github.com/nwhitehead/pyfluidsynth/issues/40, 
for solutions failed, we opted to try just installing both onto our computers
sans venv's and it works that way. Ultimately we hope to get the venv thing
figured out for this as it is so annoying for linking, but alas, this is the 
best we can manage. 


## Packages
fluidsynth: synth library, that supports soundfonts and synth channels, we 
            will be using their synths
pyfluidsynth: fluidsynth bindings for python to use 
              https://github.com/nwhitehead/pyfluidsynth


pyaudio: audio library to create audio channels for pyfluidsynth to use 

pygame: the main game engine for our game, library for the pygame and other 
        functions 

numpy: reqired for pyfluidsynth's frames 